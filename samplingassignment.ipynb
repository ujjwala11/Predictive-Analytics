{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8Amyy6gPK1dyCxgAWt+f+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hwBtj36RGuZ","executionInfo":{"status":"ok","timestamp":1768927402600,"user_tz":-330,"elapsed":2449,"user":{"displayName":"Ujjwala Thakur","userId":"03762229230670333745"}},"outputId":"f08d5675-0607-435e-edf7-01f83cfa7b15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original class distribution:\n","Class\n","0    763\n","1      9\n","Name: count, dtype: int64\n","Balanced class distribution:\n","Class\n","0    763\n","1    763\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3698490056.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  samples['Sampling3'] = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(n=n//2, random_state=3))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Accuracy Matrix ---\n","   Sampling1 Sampling2 Sampling3 Sampling4 Sampling5\n","M1  0.983333  0.866667  0.933333  0.916667  0.916667\n","M2       1.0  0.966667  0.966667       1.0       1.0\n","M3  0.683333  0.683333  0.766667  0.616667  0.666667\n","M4       0.9  0.933333  0.933333       0.9      0.95\n","M5  0.716667  0.683333       0.8  0.766667  0.783333\n","\n","--- Best Sampling Technique per Model ---\n","Model M1: Sampling1 with Accuracy 0.9833\n","Model M2: Sampling1 with Accuracy 1.0000\n","Model M3: Sampling3 with Accuracy 0.7667\n","Model M4: Sampling5 with Accuracy 0.9500\n","Model M5: Sampling3 with Accuracy 0.8000\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","data = pd.read_csv('Creditcard_data.csv')\n","\n","X = data.drop('Class', axis=1)\n","y = data['Class']\n","\n","# 2. Balancing the dataset using SMOTE\n","smote = SMOTE(random_state=42)\n","X_balanced, y_balanced = smote.fit_resample(X, y)\n","balanced_df = pd.concat([pd.DataFrame(X_balanced), pd.Series(y_balanced, name='Class')], axis=1)\n","\n","print(f\"Original class distribution:\\n{y.value_counts()}\")\n","print(f\"Balanced class distribution:\\n{y_balanced.value_counts()}\")\n","\n","\n","n = 300\n","\n","# 3. Five Different Samples\n","samples = {}\n","\n","# Sampling 1: Simple Random Sampling\n","samples['Sampling1'] = balanced_df.sample(n=n, random_state=1)\n","\n","# Sampling 2: Systematic Sampling\n","k = len(balanced_df) // n\n","samples['Sampling2'] = balanced_df.iloc[::k][:n]\n","\n","# Sampling 3: Stratified Sampling\n","\n","samples['Sampling3'] = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(n=n//2, random_state=3))\n","\n","# Sampling 4: Cluster Sampling\n","# We'll create clusters based on 'Time' blocks for demonstration\n","balanced_df['Cluster'] = pd.qcut(balanced_df['Time'], q=10, labels=False)\n","selected_clusters = np.random.choice(balanced_df['Cluster'].unique(), size=5, replace=False)\n","samples['Sampling4'] = balanced_df[balanced_df['Cluster'].isin(selected_clusters)].sample(n=n, random_state=4)\n","\n","# Sampling 5: Bootstrap Sampling (Random Sampling with Replacement)\n","samples['Sampling5'] = balanced_df.sample(n=n, replace=True, random_state=5)\n","\n","# 4. ML Models\n","models = {\n","    'M1': LogisticRegression(max_iter=1000),\n","    'M2': RandomForestClassifier(random_state=42),\n","    'M3': SVC(),\n","    'M4': DecisionTreeClassifier(random_state=42),\n","    'M5': KNeighborsClassifier()\n","}\n","\n","# 5.  Models evaluation\n","results = pd.DataFrame(index=models.keys(), columns=samples.keys())\n","\n","for s_name, sample_data in samples.items():\n","    #  train/test split\n","    X_s = sample_data.drop(['Class', 'Cluster'], axis=1, errors='ignore')\n","    y_s = sample_data['Class']\n","    X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n","\n","    for m_name, model in models.items():\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        results.loc[m_name, s_name] = accuracy_score(y_test, y_pred)\n","\n","# 6. Determine which sampling technique gives higher accuracy for each model\n","print(\"\\n--- Accuracy Matrix ---\")\n","print(results)\n","\n","best_per_model = results.idxmax(axis=1)\n","print(\"\\n--- Best Sampling Technique per Model ---\")\n","for model, best_sample in best_per_model.items():\n","    print(f\"Model {model}: {best_sample} with Accuracy {results.loc[model, best_sample]:.4f}\")"]},{"cell_type":"code","source":["# ================================\n","# Import required libraries\n","# ================================\n","\n","import pandas as pd\n","import numpy as np\n","\n","# For handling class imbalance\n","from imblearn.over_sampling import SMOTE\n","\n","# For splitting data and evaluating models\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Machine Learning models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","\n","\n","data = pd.read_csv('Creditcard_data.csv')\n","\n","\n","X = data.drop('Class', axis=1)   # all columns except target\n","y = data['Class']\n","\n","\n","#using smote\n","\n","\n","smote = SMOTE(random_state=42)\n","\n","#applying SMOTE\n","X_balanced, y_balanced = smote.fit_resample(X, y)\n","\n","\n","balanced_df = pd.concat(\n","    [pd.DataFrame(X_balanced), pd.Series(y_balanced, name='Class')],\n","    axis=1\n",")\n","\n","# class distributions before and after balancing\n","print(f\"Original class distribution:\\n{y.value_counts()}\")\n","print(f\"Balanced class distribution:\\n{y_balanced.value_counts()}\")\n","\n","\n","\n","\n","# number of records to be taken in each sample\n","n = 300\n","\n","\n","samples = {}\n","\n","\n","#  sampling 1: Simple Random Sampling\n","\n","samples['Sampling1'] = balanced_df.sample(n=n, random_state=1)\n","\n","\n","#  sampling 2: Systematic Sampling\n","\n","k = len(balanced_df) // n\n","samples['Sampling2'] = balanced_df.iloc[::k][:n]\n","\n","\n","# sampling 3: Stratified Sampling\n","\n","samples['Sampling3'] = (\n","    balanced_df\n","    .groupby('Class', group_keys=False)\n","    .apply(lambda x: x.sample(n=n // 2, random_state=3))\n",")\n","\n","\n","# sampling 4: Cluster Sampling\n","# clusters based on the 'Time' column\n","balanced_df['Cluster'] = pd.qcut(balanced_df['Time'], q=10, labels=False)\n","\n","# randomly select some clusters\n","selected_clusters = np.random.choice(\n","    balanced_df['Cluster'].unique(),\n","    size=5,\n","    replace=False\n",")\n","\n","# take samples only from the selected clusters\n","samples['Sampling4'] = (\n","    balanced_df[balanced_df['Cluster'].isin(selected_clusters)]\n","    .sample(n=n, random_state=4)\n",")\n","\n","\n","#sampling 5: Bootstrap Sampling\n","\n","samples['Sampling5'] = balanced_df.sample(\n","    n=n,\n","    replace=True,\n","    random_state=5\n",")\n","\n","\n","\n","\n","models = {\n","    'M1': LogisticRegression(max_iter=1000),\n","    'M2': RandomForestClassifier(random_state=42),\n","    'M3': SVC(),\n","    'M4': DecisionTreeClassifier(random_state=42),\n","    'M5': KNeighborsClassifier()\n","}\n","\n","\n","\n","\n","\n","results = pd.DataFrame(index=models.keys(), columns=samples.keys())\n","\n","\n","for sample_name, sample_data in samples.items():\n","\n","\n","    X_s = sample_data.drop(['Class', 'Cluster'], axis=1, errors='ignore')\n","    y_s = sample_data['Class']\n","\n","    # train test split\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_s, y_s, test_size=0.2, random_state=42\n","    )\n","\n","    # train and test each model\n","    for model_name, model in models.items():\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        #  accuracy score storing\n","        results.loc[model_name, sample_name] = accuracy_score(y_test, y_pred)\n","\n","\n","\n","\n","print(\"\\n--- Accuracy Matrix ---\")\n","print(results)\n","\n","# best sampling technique for each model\n","best_per_model = results.idxmax(axis=1)\n","\n","print(\"\\n--- Best Sampling Technique per Model ---\")\n","for model, best_sample in best_per_model.items():\n","   print(\n","        f\"Model {model}: {best_sample} \"\n","        f\"with Accuracy {results.loc[model, best_sample]:.4f}\"\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzWpMRHlUAVK","executionInfo":{"status":"ok","timestamp":1768928078703,"user_tz":-330,"elapsed":4410,"user":{"displayName":"Ujjwala Thakur","userId":"03762229230670333745"}},"outputId":"c3227c08-7a48-4dab-8bd3-5b9d86e1f6d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Original class distribution:\n","Class\n","0    763\n","1      9\n","Name: count, dtype: int64\n","Balanced class distribution:\n","Class\n","0    763\n","1    763\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2732070319.py:76: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  .apply(lambda x: x.sample(n=n // 2, random_state=3))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Accuracy Matrix ---\n","   Sampling1 Sampling2 Sampling3 Sampling4 Sampling5\n","M1  0.983333  0.866667  0.933333  0.966667  0.916667\n","M2       1.0  0.966667  0.966667  0.983333       1.0\n","M3  0.683333  0.683333  0.766667  0.683333  0.666667\n","M4       0.9  0.933333  0.933333  0.916667      0.95\n","M5  0.716667  0.683333       0.8  0.816667  0.783333\n","\n","--- Best Sampling Technique per Model ---\n","Model M1: Sampling1 with Accuracy 0.9833\n","Model M2: Sampling1 with Accuracy 1.0000\n","Model M3: Sampling3 with Accuracy 0.7667\n","Model M4: Sampling5 with Accuracy 0.9500\n","Model M5: Sampling4 with Accuracy 0.8167\n"]}]}]}